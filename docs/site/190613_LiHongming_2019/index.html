<!DOCTYPE html>
<!--[if IE 8]><html class="no-js lt-ie9" lang="en" > <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="en" > <!--<![endif]-->
<head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  
  <link rel="shortcut icon" href="../img/favicon.ico">
  <title>190613 Li, Hongming, 2019 - Cahier</title>
  <link href='https://fonts.googleapis.com/css?family=Lato:400,700|Roboto+Slab:400,700|Inconsolata:400,700' rel='stylesheet' type='text/css'>
  <link href='https://maxcdn.bootstrapcdn.com/font-awesome/4.7.0/css/font-awesome.min.css' rel='stylesheet' type='text/css'>

  <link rel="stylesheet" href="../css/theme.css" type="text/css" />
  <link rel="stylesheet" href="../css/theme_extra.css" type="text/css" />
  <link rel="stylesheet" href="//cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/styles/github.min.css">
  <link href="../css/extra.css" rel="stylesheet">
  
  <script>
    // Current page data
    var mkdocs_page_name = "190613 Li, Hongming, 2019";
    var mkdocs_page_input_path = "190613_LiHongming_2019.md";
    var mkdocs_page_url = "/cahier/190613_LiHongming_2019/";
  </script>
  
  <script src="../js/jquery-2.1.1.min.js" defer></script>
  <script src="../js/modernizr-2.8.3.min.js" defer></script>
  <script src="//cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/highlight.min.js"></script>
  <script>hljs.initHighlightingOnLoad();</script> 
  
</head>

<body class="wy-body-for-nav" role="document">

  <div class="wy-grid-for-nav">

    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side stickynav">
      <div class="wy-side-nav-search">
        <a href=".." class="icon icon-home"> Cahier</a>
        <div role="search">
  <form id ="rtd-search-form" class="wy-form" action="../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" title="Type search term here" />
  </form>
</div>
      </div>

      <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
	<ul class="tocbase current">
    
    
      


  <li class="navtree toctree-l1 inactive">
    <a class="" href="..">Home</a>
  </li>
    
      
  <li class="navtree toctree-l1 label">
    <p class="caption">2019</p>
  </li>


  

  
    <li class="navtree toctree-l1 group">
      <ul class="navtree subnav-l1 current">
          


  <li class="navtree toctree-l2 inactive">
    <a class="" href="../190723_TononiGiulio_2016/">190723</a>
  </li>
        
          


  <li class="navtree toctree-l2 inactive">
    <a class="" href="../190630_MasseNicolasY_2019/">190630 Masse, Nicolas Y., 2019</a>
  </li>
        
          


  
    
    <li class="navtree toctree-l2 page current">
      <a class="current" href="./">
        190613 Li, Hongming, 2019
          <span class="toctree-expand"></span>
      </a>
    </li>
    
      

  <li class="toctree-l2 current with-children">
    <a href="#contents">
      Contents
      <span class="toctree-expand"></span>
    </a>
  </li>



      

  <li class="toctree-l2">
    <a href="#00_abstract">
      00. Abstract
      <span class="toctree-expand"></span>
    </a>
  </li>



  <li class="toctree-l2">
    <ul class="subnav-l2 toc-hidden">
    
      
        <li class="toctree-l3">
          <a class="toctree-l4" href="#introduction">Introduction</a>
        </li>
    
      
        <li class="toctree-l3">
          <a class="toctree-l4" href="#methods">Methods</a>
        </li>
    
      
        <li class="toctree-l3">
          <a class="toctree-l4" href="#results">Results</a>
        </li>
    
      
        <li class="toctree-l3">
          <a class="toctree-l4" href="#conclusion">Conclusion</a>
        </li>
    
      
        <li class="toctree-l3">
          <a class="toctree-l4" href="#keywords">Keywords</a>
        </li>
    
    </ul>
  </li>

      

  <li class="toctree-l2">
    <a href="#01_background">
      01. Background
      <span class="toctree-expand"></span>
    </a>
  </li>



      

  <li class="toctree-l2">
    <a href="#02_methods">
      02. Methods
      <span class="toctree-expand"></span>
    </a>
  </li>



  <li class="toctree-l2">
    <ul class="subnav-l2 toc-hidden">
    
      
        <li class="toctree-l3">
          <a class="toctree-l4" href="#0201_imaging_and_clinical_data">02.01. Imaging and clinical data</a>
        </li>
    
      
        <li class="toctree-l3">
          <a class="toctree-l4" href="#0202_hippocampus_extraction">02.02. Hippocampus extraction</a>
        </li>
    
      
        <li class="toctree-l3">
          <a class="toctree-l4" href="#0203_deep_learning_for_informative_feature_extraction">02.03. Deep learning for informative feature extraction</a>
        </li>
    
      
          

  <li class="toctree-l3">
    <a href="#0204_time-to-event_prognostic_model_based_on_deep_imaging_features">
      02.04. Time-to-event prognostic model based on deep imaging features
      <span class="toctree-expand"></span>
    </a>
  </li>



  <li class="toctree-l3">
    <ul class="subnav-l3 toc-hidden">
    
      
        <li class="toctree-l4">
          <a class="toctree-l5" href="#figure_1">Figure 1</a>
        </li>
    
    </ul>
  </li>

      
    
      
        <li class="toctree-l3">
          <a class="toctree-l4" href="#0205_time-to-event_prognostic_model_when_deep_imaging_features_meet_clinical_variables">02.05. Time-to-event prognostic model when deep imaging features meet clinical variables</a>
        </li>
    
      
        <li class="toctree-l3">
          <a class="toctree-l4" href="#0206_validation_and_comparisons">02.06. Validation and comparisons</a>
        </li>
    
    </ul>
  </li>

      

  <li class="toctree-l2">
    <a href="#03_results">
      03. Results
      <span class="toctree-expand"></span>
    </a>
  </li>



  <li class="toctree-l2">
    <ul class="subnav-l2 toc-hidden">
    
      
        <li class="toctree-l3">
          <a class="toctree-l4" href="#figure_2">Figure 2</a>
        </li>
    
      
        <li class="toctree-l3">
          <a class="toctree-l4" href="#figure_3">Figure 3</a>
        </li>
    
    </ul>
  </li>

      

  <li class="toctree-l2">
    <a href="#table_1">
      Table 1
      <span class="toctree-expand"></span>
    </a>
  </li>



      

  <li class="toctree-l2">
    <a href="#figure_4">
      Figure 4
      <span class="toctree-expand"></span>
    </a>
  </li>



      

  <li class="toctree-l2">
    <a href="#figure_5">
      Figure 5
      <span class="toctree-expand"></span>
    </a>
  </li>



      

  <li class="toctree-l2">
    <a href="#04_discussion">
      04. Discussion
      <span class="toctree-expand"></span>
    </a>
  </li>



      

  <li class="toctree-l2">
    <a href="#references">
      References
      <span class="toctree-expand"></span>
    </a>
  </li>




  
        
          


  <li class="navtree toctree-l2 inactive">
    <a class="" href="../190604_PapeKatrin_2019/">190604 Pape, Katrin, 2019</a>
  </li>
        
          


  <li class="navtree toctree-l2 inactive">
    <a class="" href="../190524_KopecAshleyM_2019/">190524 Kopec, Ashley M. 2019</a>
  </li>
        
          


  <li class="navtree toctree-l2 inactive">
    <a class="" href="../190517_LynnChristopherW_2019/">190517 Lynn, Christopher W., 2019</a>
  </li>
        
          


  <li class="navtree toctree-l2 inactive">
    <a class="" href="../190517_Avena-KoenigsbergerA_2019/">190517 Avena-Koenigsberger, A., 2019</a>
  </li>
        
          


  <li class="navtree toctree-l2 inactive">
    <a class="" href="../190507_NelsonPeterT2019/">190507 Nelson, Peter T, 2019</a>
  </li>
        
          


  <li class="navtree toctree-l2 inactive">
    <a class="" href="../190427_JaafraY_LaurentJL_2018/">190427 Jaafra, Y., Laurent, J.L. 2018</a>
  </li>
        
          


  <li class="navtree toctree-l2 inactive">
    <a class="" href="../190410_DeAngelisD_DiazS_2019/">190410 DeAngelis D., Diaz S., 2019</a>
  </li>
        
          


  <li class="navtree toctree-l2 inactive">
    <a class="" href="../190311_BassettDS_BullmoreET2017/">190311 Bassett, D. S., Bullmore, E.T. 2017</a>
  </li>
        
      </ul>
    </li>
    
      
  <li class="navtree toctree-l1 label">
    <p class="caption">2018</p>
  </li>


  

  
    <li class="navtree toctree-l1 group">
      <ul class="navtree subnav-l1 current">
          


  <li class="navtree toctree-l2 inactive">
    <a class="" href="../180904/">180904</a>
  </li>
        
          


  <li class="navtree toctree-l2 inactive">
    <a class="" href="../180805_xia2018/">180805 Xia 2018</a>
  </li>
        
          


  <li class="navtree toctree-l2 inactive">
    <a class="" href="../180728_schellekens2018/">180728 Schellekens 2018</a>
  </li>
        
          


  <li class="navtree toctree-l2 inactive">
    <a class="" href="../180719_betzel2017/">180719 Betzel 2017</a>
  </li>
        
          


  <li class="navtree toctree-l2 inactive">
    <a class="" href="../180326_harari_2011/">180326 Harari 2011</a>
  </li>
        
          


  <li class="navtree toctree-l2 inactive">
    <a class="" href="../180307_avena-koenigsberger_2017/">180307 Avena Koenigsberger 2017</a>
  </li>
        
          


  <li class="navtree toctree-l2 inactive">
    <a class="" href="../180220_anzellotti_2018/">180220 Anzellotti 2018</a>
  </li>
        
      </ul>
    </li>
    
      
  <li class="navtree toctree-l1 label">
    <p class="caption">2017</p>
  </li>


  

  
    <li class="navtree toctree-l1 group">
      <ul class="navtree subnav-l1 current">
          


  <li class="navtree toctree-l2 inactive">
    <a class="" href="../171125_NIPS/">171125 NIPS</a>
  </li>
        
          


  <li class="navtree toctree-l2 inactive">
    <a class="" href="../171124_NIPS/">171124 NIPS</a>
  </li>
        
          


  <li class="navtree toctree-l2 inactive">
    <a class="" href="../170704_logan_cross/">170704 Logan Cross</a>
  </li>
        
          


  <li class="navtree toctree-l2 inactive">
    <a class="" href="../170616_cogmtg_hamamoto/">170616 CogMTG Hamamoto</a>
  </li>
        
          


  <li class="navtree toctree-l2 inactive">
    <a class="" href="../170329_bassett_2017/">170329 Bassett 2017</a>
  </li>
        
          


  <li class="navtree toctree-l2 inactive">
    <a class="" href="../170319_tni_v88n11/">170319 TNI v88n11</a>
  </li>
        
          


  <li class="navtree toctree-l2 inactive">
    <a class="" href="../170317_bassett_d_s_2017/">170317 Bassett, D.S. 2017</a>
  </li>
        
          


  <li class="navtree toctree-l2 inactive">
    <a class="" href="../170314_yoshimori_t/">170314 Yoshimori, T.</a>
  </li>
        
          


  <li class="navtree toctree-l2 inactive">
    <a class="" href="../170216_hasegawa_t/">170216 Hasegawa, T.</a>
  </li>
        
      </ul>
    </li>
    
      
  <li class="navtree toctree-l1 label">
    <p class="caption">2016</p>
  </li>


  

  
    <li class="navtree toctree-l1 group">
      <ul class="navtree subnav-l1 current">
          


  <li class="navtree toctree-l2 inactive">
    <a class="" href="../160604_kano_m/">160604 Kano, M.</a>
  </li>
        
          


  <li class="navtree toctree-l2 inactive">
    <a class="" href="../160526_osumi_semi/">160526 Osumi semi</a>
  </li>
        
          


  <li class="navtree toctree-l2 inactive">
    <a class="" href="../160523_okada_y/">160523 Okada, Y.</a>
  </li>
        
      </ul>
    </li>
    
  </ul>
      </div>
      &nbsp;
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" role="navigation" aria-label="top navigation">
        <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
        <a href="..">Cahier</a>
      </nav>

      
      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="breadcrumbs navigation">
  <ul class="wy-breadcrumbs">
    <li><a href="..">Docs</a> &raquo;</li>
    
      
        
          <li>2019 &raquo;</li>
        
      
    
    <li>190613 Li, Hongming, 2019</li>
    <li class="wy-breadcrumbs-aside">
      
    </li>
  </ul>
  <hr/>
</div>
          <div role="main">
            <div class="section">
              
                <!--
Filename:   190613_LiHongming_2019.md
Project:    /Users/shume/Documents/Cahier
Author:     shumez <https://github.com/shumez>
Created:    2019-06-13 16:28:6
Modified:   2019-06-15 11:33:45
-----
Copyright (c) 2019 shumez
-->

<h1 id="19-06-13">19-06-13<a class="headerlink" href="#19-06-13" title="Permanent link">¬∂</a></h1>
<blockquote>
<p>Li, H., Habes, M., Wolk, D.A. and Fan, Y., 2019. A deep learning model for early prediction of Alzheimer's disease dementia based on hippocampal MRI. arXiv preprint arXiv:1904.07282.</p>
</blockquote>
<pre><code class="tex">
</code></pre>

<p><a href="https://arxiv.org/abs/1904.07282">Website</a> | <a href="https://arxiv.org/abs/1904.07282">PDF</a> | [Mendeley]</p>
<h2 id="contents">Contents<a class="headerlink" href="#contents" title="Permanent link">¬∂</a></h2>
<ul>
<li><a href="#00_abstract">00. Abstract</a></li>
<li><a href="#01_background">01. Background</a></li>
<li><a href="#02_methods">02. Methods</a><ul>
<li><a href="#0201_imaging_and_clinical_data">02.01. Imaging and clinical data</a></li>
<li><a href="#0202_hippocampus_extraction">02.02. Hippocampus extraction</a></li>
<li><a href="#0203_deep_learning_for_informative_feature_extraction">02.03. Deep learning for informative feature extraction</a></li>
<li><a href="#0204_time-to-event_prognostic_model_based_on_deep_imaging_features">02.04. Time-to-event prognostic model based on deep imaging features</a></li>
<li><a href="#0205_time-to-event_prognostic_model_when_deep_imaging_features_meet_clinical_variables">02.05. Time-to-event prognostic model when deep imaging features meet clinical variables</a></li>
<li><a href="#0206_validation_and_comparisons">02.06. Validation and comparisons</a></li>
</ul>
</li>
<li><a href="#03_results">03. Results</a></li>
<li><a href="#04_discussion">04. Discussion</a></li>
</ul>
<h2 id="00_abstract">00. Abstract<a class="headerlink" href="#00_abstract" title="Permanent link">¬∂</a></h2>
<h3 id="introduction">Introduction<a class="headerlink" href="#introduction" title="Permanent link">¬∂</a></h3>
<blockquote>
<p>It is challenging at baseline to predict when and which individuals who meet criteria for mild cognitive impairment (MCI) will ultimately progress to Alzheimer‚Äôs disease (AD) dementia. </p>
</blockquote>
<h3 id="methods">Methods<a class="headerlink" href="#methods" title="Permanent link">¬∂</a></h3>
<blockquote>
<p>A deep learning method is developed and validated based on MRI scans of 2146 subjects (803 for training and 1343 for validation) to predict MCI subjects‚Äô progression to AD dementia in a time- to-event analysis setting.</p>
</blockquote>
<h3 id="results">Results<a class="headerlink" href="#results" title="Permanent link">¬∂</a></h3>
<blockquote>
<p>The deep learning time-to-event model predicted individual subjects‚Äô progression to AD dementia with a concordance index (C-index) of 0.762 on 439 ADNI testing MCI subjects with follow-up duration from 6 to 78 months (quartiles: [24, 42, 54]) and a C-index of 0.781 on 40 AIBL testing MCI subjects with follow-up duration from 18-54 months (quartiles: [18, 36,54]). The predicted progression risk also clustered individual subjects into subgroups with significant differences in their progression time to AD dementia (p&lt;0.0002). Improved performance for predicting progression to AD dementia (C- index=0.864) was obtained when the deep learning based progression risk was combined with baseline clinical measures.</p>
</blockquote>
<h3 id="conclusion">Conclusion<a class="headerlink" href="#conclusion" title="Permanent link">¬∂</a></h3>
<blockquote>
<p>Our method provides a cost effective and accurate means for prognosis and potentially to facilitate enrollment in clinical trials with individuals likely to progress within a specific temporal period. </p>
</blockquote>
<h3 id="keywords">Keywords<a class="headerlink" href="#keywords" title="Permanent link">¬∂</a></h3>
<blockquote>
<p>deep learning; hippocampus; time-to-event analysis; Alzheimer‚Äôs disease</p>
</blockquote>
<h2 id="01_background">01. Background<a class="headerlink" href="#01_background" title="Permanent link">¬∂</a></h2>
<blockquote>
<p>Individuals with mild cognitive impairment (MCI) are at a higher risk to develop dementia (usually due to Alzheimer‚Äôs Disease (AD)), with an annual progression rate up to 10~20% [1]. Although clinical criteria for MCI and AD have been developed to formalize assessment of the gradual progression of the disease, it remains difficult at baseline to predict when and which individuals who meet criteria for MCI will ultimately progress to AD dementia.</p>
</blockquote>
<ul>
<li>MCI<ul>
<li>pMCI (progressive)</li>
<li>sMCI (stable)</li>
</ul>
</li>
</ul>
<blockquote>
<p>The early prediction of AD dementia has been typically modeled as a pattern classification problem. For instance, by <a href="#">dichotomizing</a> MCI subjects into <strong>progressive MCIs (<a href="#">pMCI</a>s)</strong> and <strong>stable MCIs (<a href="#">sMCI</a>s)</strong> based on a cut-off threshold of follow-up duration, a binary classifier is then trained based on baseline data to distinguish pMCIs from sMCIs. To early predict AD dementia based on neuroimaging data, machine learning techniques have been adopted to build classifiers upon imaging data, and prominent brain structural differences have been identified between AD and cognitively normal (NC) subjects as well as between pMCI and sMCI subjects within the medial temporal lobe (MTL), including regions such as hippocampus and entorhinal cortex <sup>[2],[3],[4],[5],[6],<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5511557/pdf/nihms874419.pdf" title="Rathore, S., Habes, M., Iftikhar, M.A., Shacklett, A. and Davatzikos, C., 2017. A review on neuroimaging-based classification studies and associated feature extraction methods for Alzheimer's disease and its prodromal stages. NeuroImage, 155, pp.530-548.">7</a>,[8],[9],[10],[11]</sup>. The existing classification studies typically adopt relatively simple imaging measures, such as brain tissue density, volume, cortical thickness, and geometric characteristics of hippocampus. These hand-crafted measures might be less discriminative for the AD prognosis. For predicting MCI subjects‚Äô progression to AD dementia it is a suboptimal strategy to distinguish pMCI from sMCI subjects in a classification setting in that the classification performance is hindered on the cut-off threshold of follow-up duration to define pMCI and sMCI, and the cohorts of pMCI and sMCI subjects are highly heterogeneous regardless of the threshold used. More importantly, the classification based early prediction of AD dementia does not provide specific information about the timing of when MCI patients cross the threshold to AD dementia.</p>
<p>Recent studies have moved the focus onto the prediction of timing of progression to AD over the follow-up duration using time-to-event analysis techniques <sup>[12],[13],[14],[15],[16]</sup>. Clinical and imaging based measures at baseline and their longitudinal change trajectory have been adopted for predicting MCI subjects‚Äô progression to AD dementia, and promising performance have been achieved. However, only simple imaging features or individual clinical measures have been investigated, which might be less discriminative for the prognosis.</p>
<p>To better predict individual MCI subjects‚Äô progression to AD dementia based on baseline structural MRI data, we develop a deep learning framework to extract informative features from hippocampal MRI data, and build a prognostic model upon the extracted features to predict progression of MCI subjects in a time-to-event analysis setting. We have evaluated the proposed method using baseline structural MRI data of subjects from the Alzheimer‚Äôs Disease Neuroimaging Initiative (ADNI) <sup>[17],[18],[19]</sup> (including ADNI-1, ADNI-GO&amp;2), and the Australian Imaging Biomarkers and Lifestyle Study of Aging (AIBL) <sup>[20]</sup>. We also compared the deep learning based imaging features with conventionally hand-crafted imaging features.</p>
</blockquote>
<h2 id="02_methods">02. Methods<a class="headerlink" href="#02_methods" title="Permanent link">¬∂</a></h2>
<h3 id="0201_imaging_and_clinical_data">02.01. Imaging and clinical data<a class="headerlink" href="#0201_imaging_and_clinical_data" title="Permanent link">¬∂</a></h3>
<blockquote>
<p>We included data from the ADNI (http://adni.loni.usc.edu) and AIBL (www.aibl.csiro.au) cohorts, consisting of baseline MRI scans of 1711 ADNI subjects and 435 AIBL subjects. The data were downloaded on April 05, 2017. For up-to-date information, see www.adni-info.org.</p>
<p>We used MRI data (n=803 scans) from the ADNI-1 to train the proposed prognostic model. Then we validated the proposed model with independent data from the ADNI-GO&amp;2 and the AIBL. For the ADNI-GO cohort only new add-on subjects (no overlap with ADNI-1) were used for the validation. The present study included all MCI subjects with baseline MRI scans and at least one clinical follow-up data point, including those who converted back from MCI to Normal Cognition. The characteristics of the cohorts included in this study are summarized in tables S1, S2, and S3 of supplementary material. In the present study, the ADNI-1 scans were collected using 1.5T scanners, the ADNI-GO&amp;2 scans were collected using 3T scanners, and the AIBL scans were collected using 3T scanners.</p>
<p>Clinical variables include age, sex, education, APOE4 (Apolipoprotein E4), the 13-item version of the Alzheimer‚Äôs Disease Assessment Scale-Cognitive subscale (ADAS-Cog13), Rey Auditory Verbal Learning Test (RAVLT) immediate, RAVLT learning, Functional Assessment Questionnaire (FAQ), and Mini-Mental State Examination (MMSE), were obtained for MCI subjects from the ADNI cohorts. Particularly, the ADAS-Cog13 consists of 11-item (word recall, commands, constructional praxis, naming, ideational praxis, orientation, word recognition, remembering test instructions, comprehension, word finding difficulty, spoken language ability) ADAS-cog plus 2 additional items (delayed word recall and number cancellation).</p>
<p>We also analyzed MCI subjects of the ADNI-GO&amp;2 cohorts in terms of their amyloid positive status. Particularly, amyloid positive subjects were defined as those with a CSF (cerebrospinal fluid) AŒ≤42 (amyloid beta peptide 42) level below 192 pg/mL or with a summary AV-45 (Florbetapir-F18) cortical standardized uptake value ratio (SUVR) normalized by the whole cerebellum above 1.11 when CSF AŒ≤42 level was not available.</p>
</blockquote>
<h3 id="0202_hippocampus_extraction">02.02. Hippocampus extraction<a class="headerlink" href="#0202_hippocampus_extraction" title="Permanent link">¬∂</a></h3>
<blockquote>
<p>T1 MRI scans were registered to the MNI space using affine registration and resampled at a spatial resolution of 1 √ó 1 √ó 1 mm3. Bilateral hippocampal regions were segmented from the T1 images for each subject using the local label learning (LLL) [21] algorithm with 100 hippocampus atlases obtained from a preliminary release of the EADC-ADNI harmonized segmentation protocol project (www.hippocampal- protocol.net) [22]. A 3D bounding box of size 29 √ó 21 √ó 55 was then adopted to extract hippocampus regions from the T1 images using the segmentation labels. These hippocampal data were used to extract features and build the prognostic models.</p>
</blockquote>
<h3 id="0203_deep_learning_for_informative_feature_extraction">02.03. Deep learning for informative feature extraction<a class="headerlink" href="#0203_deep_learning_for_informative_feature_extraction" title="Permanent link">¬∂</a></h3>
<blockquote>
<p>A deep learning model of convolutional neural networks (CNNs) with residual connections was trained to learning informative features for distinguishing AD from NC subjects. As illustrated in Fig. 1B, the left and right hippocampal images were inputs to the deep learning model with two streams, each for one hippocampus. Each stream of the deep learning model consisted of 1 convolutional layer (Conv), followed by 3 residual blocks (ResBlocks) [23], and 1 global average pooling (GAP) layer [24]. As illustrated in Fig. 1C, each of the ResBlocks had 2 Conv layers with a direct connection between its input and output. These two streams‚Äô outputs were then flattened and concatenated as input to a fully connected layer (FC) for building the classification model. Rectified linear units (ReLUs) were used as nonlinear activation functions and max pooling layers were adopted to learn features at multiple scales. Batch normalization (BN) was adopted in our deep learning model [25], and the GAP layers facilitated visualization of the learned features through AD-like relevance maps [24]. Specifically, each of the Conv layers contained 32 kernels, the ResBlocks 1, 2, and 3 contained 32, 64, and 128 kernels respectively, and all these kernels had the same size of 3 √ó 3 √ó 3. The max pooling layer had a stride of 2 √ó 2 √ó 2 and a kernel size of 2 √ó 2 √ó 2. Outputs of the GAP layers were concatenated and followed by a dropout operation with a ratio of 0.5 to form an input vector for the FC to make the diagnosis of the input data. Once the deep classification model was obtained, new image could be fed into the deep learning model and its deep learning features (1 √ó 256 feature vector in this study) were extracted as the output of the GAP layers and used as the input to time-to-event prognostic models.</p>
</blockquote>
<h3 id="0204_time-to-event_prognostic_model_based_on_deep_imaging_features">02.04. Time-to-event prognostic model based on deep imaging features<a class="headerlink" href="#0204_time-to-event_prognostic_model_based_on_deep_imaging_features" title="Permanent link">¬∂</a></h3>
<blockquote>
<p>Based on the deep learning features, a prognostic model for predicting individual subject‚Äôs timing of progression to AD dementia was built using LASSO regularized Cox regression model [26]. Particularly, the prognostic model was trained based on the ADNI-1 cohort, and its prognostic performance was evaluated based on the ADNI-GO&amp;2 and AIBL cohorts. The overall training and validation procedures are illustrated in Fig. 1A. The LASSO model‚Äôs regularization parameter was optimized using 10-fold cross-validation based on the training data. The time-to-event prognostic model estimates overall risk scores to progress to AD dementia for individuals. Individuals with higher risk scores will progress to AD sooner than those with lower risk scores. An annual probability value of progression to AD can be estimated based on the risk score, given a baseline hazard (progression to AD) function, which could be estimated based on training cohort [27].</p>
</blockquote>
<h6 id="figure_1">Figure 1<a class="headerlink" href="#figure_1" title="Permanent link">¬∂</a></h6>
<blockquote>
<p><img alt="Fig.1" src="#" /></p>
<p>Fig. 1. Schematic illustration of the deep learning based AD prognosis. (A) A general flowchart for training and validating the prognostic model. (B) Deep network architecture for data-driven hippocampus-based AD diagnosis. (C) residual block. L: left hippocampus; R: right hippocampus. (NC: cognitively normal control; AD: Alzheimer‚Äôs disease; MCI: mild cognitive impairment; Conv: convolutional layer; BN: batch normalization; ReLU: rectified linear unit; ResBlock: residual block; Concat: concatenation layer; FC: fully connected layer).</p>
</blockquote>
<h3 id="0205_time-to-event_prognostic_model_when_deep_imaging_features_meet_clinical_variables">02.05. Time-to-event prognostic model when deep imaging features meet clinical variables<a class="headerlink" href="#0205_time-to-event_prognostic_model_when_deep_imaging_features_meet_clinical_variables" title="Permanent link">¬∂</a></h3>
<blockquote>
<p>Based on the deep learning prognostic model, risk of progression to AD could be estimated for each MCI subject. The estimated risk was combined with clinical variables including age, sex, education, APOE4, ADAS-Cog13, RAVLT immediate, RAVLT learning, FAQ, and MMSE to build a second prognostic model using Cox regression [28]. The prognostic model was trained based on the ADNI-1 MCI subjects and evaluated based on the ADNI-GO&amp;2 data. Since the AIBL did not provide all these clinical measures, we did not evaluate the prognostic model based on the AIBL data.</p>
<p>To evaluate significance of the deep learning features when combined with the clinical measures for the prediction of AD dementia, we had also built another prognostic model of MCI subjects based on the AD score (probability) estimated by the deep AD/NC classification model and baseline clinical variables using Cox regression. The prognostic model was also trained on the ADNI-1 data and evaluated on the ADNI-GO&amp;2 data.</p>
</blockquote>
<h3 id="0206_validation_and_comparisons">02.06. Validation and comparisons<a class="headerlink" href="#0206_validation_and_comparisons" title="Permanent link">¬∂</a></h3>
<blockquote>
<p>We evaluated the proposed method and compared it with state-of-the-art alternative image feature extraction methods [29] based on the same training and validation datasets. All the models were trained using the ADNI-1 data, and validated using the ADNI-GO&amp;2 and AIBL data. We compared the deep learning models with those built on conventional hippocampal imaging features, including shape features and texture features (Details in supplementary material). Particularly, two alternative models were built on shape features only and a combination of shape and texture features (denoted as shape &amp; texture thereafter) respectively.</p>
<p>In order to directly access reproducibility of our deep learning features across scanners with different magnetic field strengths, we obtained 1.5T and 3T scans of the same subjects of the ADNI-1 cohort (n=113, 37 NC, 50 MCI, and 26 AD), computed their deep learning features, and finally measured comparability between deep learning features of 1.5T and 3T scans and between their predicted risk scores for individual subjects.</p>
<p>In order to evaluate the deep imaging features‚Äô discriminative power, we compared its performance for distinguishing AD from NC subjects with alternative classification models based on conventional hippocampal shape and texture features. Random forests (RF) [30] were adopted to build classification models upon the conventional features (Details in supplementary material). Classification accuracy, receiver operating characteristic (ROC) curve, and area under ROC curve (AUC) were used to evaluate all the models under comparison. We adopted Delong test to compare AUC measures obtained by different models.</p>
<p>In order to investigate how different parts of the hippocampal imaging data contributed to the classification, class relevance maps [24] with respect to AD were obtained for all the subjects from the validation cohorts, and mean relevance maps of different subject groups including NC, sMCI, pMCI, and AD were obtained respectively. MCI subjects who progressed to AD from 0.5 to 3 years from the baseline scan were defined as pMCI (mean/standard deviation: 1.69/0.93 years, quartiles: [1, 2, 2.5] years), otherwise defined as sMCI for this visualization analysis. It is worth noting that we do not need to define pMCI and sMCI for the time-to-event analyses.</p>
<p>We further investigated the associations between the deep hippocampal imaging features and clinical measures including MMSE, ADAS-cog13, RAVLT immediate, RAVLT learning, FAQ, AùõΩ status (positive or negative), and APOE4, Pearson‚Äôs correlation coefficients were adopted to measure the potential associations.</p>
<p>In order to evaluate the performance of prognostic models built on different kinds of imaging features, concordance index (C-index) and time-dependent ROC curves were adopted to evaluate their accuracy. Particularly, the C-index measures proportion of all possible pairs of subjects, at least one of whom has progressed to AD dementia, in which the predicted progression risk (probability) is larger for the subjects who progressed to AD dementia in a shorter time [31], while the time-dependent ROC curves access prediction performance of progression of AD dementia at different observed times [32]. The time- dependent ROC curves were adopted so that the performance of prognostic models could be evaluated using ROC curves that are widely used to illustrate sensitivity and specificity of a continuous diagnostic marker for predicting a binary clinical outcome variable in classification studies. Since the status of progression of AD is dependent on the follow-up time, binary status of progression of AD could be obtained at different cut-off time points to compute their corresponding ROC curves, yielding time-dependent ROC curves [33]. A nonparametric approach [34] was adopted to estimate and compare C- index values, and nonparametric inverse probability of censoring weighting estimators [32] were adopted to obtain and compare time-dependent ROC based measures. The prognostic accuracy was also evaluated for amyloid positive MCI subjects alone. All the measures were calculated in R.</p>
<p>We investigated the subject stratification results based on the prognostic risks of progression to AD dementia for MCI subjects. Specifically, all the MCI subjects were categorized into 3 sub-groups with low, middle, and high predicted risks of progression to AD dementia, and Kaplan-Meier plot was adopted to investigate their progression to AD dementia based on real follow-up duration information.</p>
</blockquote>
<h2 id="03_results">03. Results<a class="headerlink" href="#03_results" title="Permanent link">¬∂</a></h2>
<blockquote>
<p>Mean of correlations between the deep learning features of 1.5T and 3T scans of the 113 ADNI-1 subjects was 0.955¬±0.023 (quantiles: [0.930, 0.958, 0.979]), and mean of intra-class correlation coefficients (ICCs) across all the deep learning features was 0.950¬±0.026 (quantiles: [0.925, 0.951, 0.978]), demonstrating that the deep learning features were robust to magnetic field strength differences. The ICC between the predicted risk scores of the 1.5T and 3T scans was 0.982, demonstrating that the prediction performance was also robust to the differences in magnetic field strength.</p>
<p>The deep learning classifier‚Äôs accuracy rates for distinguishing AD from NC subjects on the ADNI- GO&amp;2 and AIBL cohorts were 0.900 and 0.929 respectively, and AUC values were 0.956 and 0.958 respectively. Delong test indicated that the deep learning classifier performed significantly better than the RF based classifiers in terms of their AUC measures (p&lt;0.008). Fig. S2 (supplementary material) shows ROC curves of the classifiers under comparison.</p>
<p>Fig. 2 illustrates the mean AD-like relevance maps for NC, sMCI, pMCI, and AD groups of the ADNI-GO&amp;2 cohorts. We found that the relevance map of the AD subjects highlighted both the anterior and posterior hippocampus, the pMCI subjects‚Äô highlighted the anterior hippocampus, and maps of the NC and sMCI subjects had relatively weak relevance.</p>
</blockquote>
<h6 id="figure_2">Figure 2<a class="headerlink" href="#figure_2" title="Permanent link">¬∂</a></h6>
<blockquote>
<p>![Figure.2][fig02]</p>
<p>Fig. 2. Mean AD-like relevance maps for different subject groups, demonstrating the discriminative sub- regions that distinguish AD from NC and characterizing the imaging patterns along the pathological progression of AD. Warmer color indicates severer brain degeneration and more relevant to the progression to AD and cool color indicates rare brain degeneration and irrelevant to the progression to AD. The hippocampus panel shows mean hippocampal segmentation maps across subjects in different views (A: anterior, P: posterior, M: medial, L: lateral, S: superior, I: inferior). The mean maps have values in [0,1], indicating each voxel‚Äôs percentage for being located in the hippocampus across subjects whose brain images were registered to the MNI space. The segmentation maps serve as spatial references to the hippocampal locations for the AD relevance maps. NC: cognitively normal control; AD: Alzheimer‚Äôs disease; MCI: mild cognitive impairment; sMCI: stable MCI; pMCI: progressive MCI.</p>
</blockquote>
<h3 id="_1"><a class="headerlink" href="#_1" title="Permanent link">¬∂</a></h3>
<blockquote>
<p>Fig. 3 shows that the correlation coefficients between top 50 deep learning features with largest weights in the deep learning classifier and cognitive measures and biomarkers across all subjects of the ADNI-GO&amp;2 cohorts, indicating that the deep learning features were significantly correlated with clinical measures (Pearson‚Äôs correlation, p&lt;0.05). Fig. S3 (supplementary material) shows that amyloid negative MCI subjects had significantly lower progression risks compared with amyloid positive subjects (p&lt;6.0 √ó 10‚àí13, Wilcoxon rank sum tests). These results demonstrated that the deep imaging features were informative to capture the characteristics of AD related biomarkers and cognitive measures.</p>
</blockquote>
<h6 id="figure_3">Figure 3<a class="headerlink" href="#figure_3" title="Permanent link">¬∂</a></h6>
<blockquote>
<p>![Figure.3][fig03]</p>
<p>Fig. 3. Top 50 features with largest weights in the deep classification model for AD/NC diagnosis were significantly correlated to cognitive/biological measures across all the subjects of the ADNI-GO&amp;2 cohorts. The box plots show median/quartiles of correlation coefficients between pairs of one cognitive/biological measure and each of top 50 deep learning features. The outliers are plotted using the ‚Äò+‚Äô symbol. (MMSE: Mini‚ÄìMental State Examination; ADAS-cog13: 13-item version of the Alzheimer‚Äôs Disease Assessment Scale-Cognitive subscale; RAVLT: Rey Auditory Verbal Learning Test; FAQ: Functional Assessment Questionnaire; AŒ≤: amyloid beta peptide 42; APOE4: Apolipoprotein E4).</p>
</blockquote>
<h3 id="_2"><a class="headerlink" href="#_2" title="Permanent link">¬∂</a></h3>
<blockquote>
<p>The prediction accuracy of the prognostic models built upon hippocampal imaging features are summarized in Table 1. The deep learning model predicted the ADNI-GO&amp;2 MCI subjects‚Äô progression to AD dementia with a C-index of 0.762, significantly better than those built upon conventional shape and texture image features (p&lt;0.03 [34]). The deep leaning model predicted the AIBL MCI subjects‚Äô progression to AD dementia with a C-index of 0.781, better than those built upon conventional shape (p=0.037). However, the difference between prediction models built on the deep learning imaging features and the shape &amp; texture image features was not statistically significant (p=0.694 [34]). As shown in Fig.4 (top row), the AUC measures of time-dependent ROC curves obtained by the deep learning based model on follow-up durations from year 1 to year 3 were 0.75, 0.778, and 0.813 respectively on the ADNI-GO&amp;2 cohorts, better than the alternative models (the differences were significant when compared with prediction models built on the shape features at year 2, and on both the shape and shape &amp; texture features at year 3, p&lt;0.04 [32]).</p>
</blockquote>
<h6 id="table_1">Table 1<a class="headerlink" href="#table_1" title="Permanent link">¬∂</a></h6>
<blockquote>
<p>![Table.1][tbl01]</p>
<p>Table 1. Prediction performance of prognostic models built upon different types of features.</p>
</blockquote>
<h6 id="figure_4">Figure 4<a class="headerlink" href="#figure_4" title="Permanent link">¬∂</a></h6>
<blockquote>
<p>![Figure.4][fig04]</p>
<p>Fig. 4. Time-dependent ROC curves of prognostic models built upon different imaging features at follow- up durations from year 1 to year 3 on the ADNI-GO&amp;2 cohorts. Top row: all the ADNI-GO&amp;2 MCI subjects; Bottom row: Amyloid positive MCI subjects of the ADNI-GO&amp;2 cohorts.</p>
</blockquote>
<h3 id="_3"><a class="headerlink" href="#_3" title="Permanent link">¬∂</a></h3>
<blockquote>
<p>The prediction model built on the deep learning imaging features predicted the amyloid positive subjects‚Äô progression to AD with a C-index of 0.733, better than those built on the conventional shape and shape &amp; texture imaging features (with C-index of 0.656 and 0.680 respectively, p=0.004 and 0.06 [34]). As shown in Fig.4 (bottom row), the AUC measures of time-dependent ROC curves obtained by the deep imaging feature based model at follow-up durations from year 1 to year 3 were 0.731, 0.762, and 0.789 respectively, better than the alternative models (the differences were significant when compared with prediction models built on the shape features at year 2 and 3, p&lt;0.05 [32]). The deep learning feature based model also performed better than prediction models built upon hippocampal volumes (supplementary material).</p>
<p>The predicted progression risk to AD dementia also clustered MCI subjects from ADNI-GO&amp;2 into subgroups with significant differences in their timing of progression (p&lt;0.0002, Log-rank test) with age, sex, education and APOE4 status as covariates, as demonstrated by the Kaplan-Meier plots in Fig. 5.</p>
</blockquote>
<h6 id="figure_5">Figure 5<a class="headerlink" href="#figure_5" title="Permanent link">¬∂</a></h6>
<blockquote>
<p>![Figure.5][fig05]</p>
<p>Fig. 5. Kaplan-Meier plots of MCI subgroups with different progression risks in terms of conversion to AD estimated by the deep learning prediction model on testing MCI subjects of the ADNI-GO&amp;2 cohorts (Low: the 1st quartile, High: the 4th quartile, Middle: 2nd and 3rd quartiles). The subgroups were significantly different in their conversion timing to AD (Log-rank test, p&lt;0.0002).</p>
</blockquote>
<h3 id="_4"><a class="headerlink" href="#_4" title="Permanent link">¬∂</a></h3>
<blockquote>
<p>The prediction model built upon the predicted AD dementia progression risks (based on deep learning features) and baseline clinical measures achieved improved performance (C-index=0.864) on the ADNI-GO&amp;2 cohorts, significantly better than the model built on clinical measures alone (C- index=0.848, p=0.05). As summarized in Table S4 and S5, RAVLT_immediate, FAQ, and the deep learning features were top 3 predictors for predicting progression to AD dementia (p&lt;1 √ó 10‚àí5). We have further estimated performance of prediction models built on different combinations of imaging features, AŒ≤ measures, APOE4 status, and cognition measures, in addition to demographic data (age, sex, and education). As summarized in Tables S6 and S7 (supplementary material), the combination of the deep learning imaging features and demographic measures had significantly better prediction performance than the combination of MMSE and demographic measures (p=0.0004). Among the cognitive measures, ADAS-cog13 had the best prediction performance when combined with demographic measures, and the difference in terms of prediction performance between the deep learning imaging features and the ADAS- Cog13 was not statistically significant when combined with the demographic data (p=0.257). The deep learning imaging features had similar performance as AùõΩ and APOE4 measures when combined with all the cognitive measures.</p>
</blockquote>
<h2 id="04_discussion">04. Discussion<a class="headerlink" href="#04_discussion" title="Permanent link">¬∂</a></h2>
<blockquote>
<p>In this study, we proposed a deep learning framework for early prognosis of AD dementia based on the hippocampal MRI data. We trained a deep learning classifier based on the ADNI-1 cohort for extracting informative imaging features, and built a time-to-event prognostic model on these features to predict the progression to AD dementia for MCI subjects of the ADNI-GO&amp;2 and AIBL cohorts. We demonstrated that the deep learning prediction model could achieve promising performance for predicting MCI subjects‚Äô progression to AD dementia and identifying subgroups of subjects with different progression patterns.</p>
<p>Deep learning techniques have been explored for the prognosis of AD dementia [35-38]. These studies adopted a classification setting to predict MCI progression, and had to dichotomize the training data into progressive or stable MCIs based on certain cut-off threshold. Therefore, their prediction performance was dependent on their cut-off thresholds. Instead of formulating the early prediction of MCI subjects‚Äô progression to AD dementia as a binary classification problem, we built a prognostic model under a time-to-event analysis setting. The time-to-event prognostic model took into consideration the timing of progression to AD dementia, and could estimate the timing/risk of progression to AD dementia for each individual subject, which could be used to monitor their disease progression longitudinally. Our prediction results could also be analyzed using the conventional ROC curves, i.e., the time dependent ROC curves. On the other hand, the estimated risk could also facilitate stratification of MCI subjects to identify those with higher risk to progress to AD dementia as demonstrated in Fig. 5.</p>
<p>A very striking finding in our study was the clear advantage of the use of deep learning hippocampal features in predicting progression to dementia compared with the hippocampal volume, which is frequently used in the literatures as a marker of neurodegeneration [39]. Maybe due to practicality in assessment, most of the attention has been given so far for the volumetric features of the hippocampus rather than other features in exploring dementia. However, even in structural MRI the dementia related changes in the hippocampus seem to be better exploited with the deep learning features we are proposing for more robust progression prediction.</p>
<p>Several studies have specifically focused on the hippocampus for early diagnosis of AD and built predictive models upon anatomical features such as the hippocampal volume and shape based measures and image intensity texture features [5, 6, 40-44]. Although promising performance of the hippocampus shape features [45-47], texture features [48] and CNNs based features [43, 49] has been demonstrated for the classification of AD patients, their classification setting ignored the timing of progression to AD dementia. Moreover, it is challenging to define the pMCI and sMCI under a classification setting due to high heterogeneity of the AD continuum. Several recent studies [12-15] have focused on the prediction of time of progression to AD dementia under a time-to-event analysis setting; however, relatively simple features, e.g., volumetric and geometric measures, were included in the prognostic analysis. The discriminative power of these hand-crafted measures are relatively limited, especially when used for more complex prognostic tasks. As demonstrated in Fig. S2, the deep imaging features performed significantly better than conventional shape and texture features for distinguishing AD from NC subjects on both the ADNI-GO&amp;2 and AIBL cohorts, indicating that the deep imaging features are more discriminative, and may have better potentials for characterizing the hippocampal changes related to AD dementia. It also demonstrated good generalization performance across different cohorts.</p>
<p>Sub-regions of the hippocampus, as shown in Fig. 2, contributed differently to characterize the AD related differences. The relevance map of the AD subjects highlighted both the anterior and posterior hippocampus, the pMCI subjects‚Äô map highlighted the anterior hippocampus, and maps of the NC and sMCI subjects had relatively weak relevance. These results were largely consistent with patterns of MCI and AD subjects described in existing studies [50, 51]. It also suggested that the anterior hippocampus was involved along the progression to AD prior to the posterior part [52, 53]. These relevance patterns have demonstrated that the deep features were indeed extracted from the AD related hippocampus regions. As the CNNs was optimized to learn discriminative imaging features, representing an evolution of imaging features from low-level intensity contrast to high-level complex patterns, for better differentiating AD from NC, it is speculated that the learned imaging features might reflect the AD relevant microstructural alternations in the hippocampal regions, and different weights of sub-regions demonstrated their involvement in these changes. These imaging alternations might be results of pathophysiological changes such as neuronal loss [54].</p>
<p>As shown in Fig. 3, we also found that the deep learning features were significantly correlated with cognitive measures and AD related biomarkers. Moreover, we found that amyloid positive MCIs who have molecular evidence of prodromal AD had higher predicted AD dementia progression risks than amyloid negative MCIs [55].</p>
<p>Different quantitative evaluation measures, as shown in Table 1 and Fig. 4, have demonstrated that the deep imaging features‚Äô superiority for predicting the MCI subjects‚Äô progression to AD on different cohorts, compared with the conventional shape and texture features. The deep learning prediction model also performed significantly better than other prediction models built upon conventional imaging features for amyloid positive subjects. Fig. 4 shows that the AUC values of the AùõΩ positive MCI subjects were smaller than those of all MCI subjects. This difference in AUC values was a result of the difference in the testing data sets, and the risk scores of individual AùõΩ positive MCI subjects were the same regardless of the computation of AUC values. Comparisons in terms of AUC values should be based on the same data set since the AUC values are summary measures for certain testing data sets. Nonetheless, it is possible that measures of neurodegeneration in the hippocampus would have better predictive power than amyloid status alone, as the former measure is more tightly linked to disease progression.</p>
<p>The prognostic performance of the prognostic model built on the combination of deep learning imaging features and clinical measures worked significantly better than that built on clinical measures alone. Particularly, RAVLT_immediate, FAQ, and the deep learning imaging features were top 3 predictors for predicting the MCI subjects‚Äô progression to AD dementia, as summarized in Table S4 and S5. The prognostic models built on a combination of demographic data (age, sex, education), cognitive measures, and deep learning features had better or similar prediction performance than prognostic models built on combinations of demographic data, cognitive measures, and APOE4 statuses or AùõΩ measures as summarized in tables 1, S6, and S7, indicating that the deep learning imaging features could serve as a surrogate if APOE4 or AùõΩ measures are not available.</p>
<p>Recently studies have also demonstrated promising performance for predicting individual subjects‚Äô timing of progression to AD dementia using time-to-event analysis techniques [12-15]. Particularly, clinical and imaging based measures at baseline [12, 13, 15] and their longitudinal change trajectory [14] have been adopted for predicting MCI subjects‚Äô progression to AD dementia. In conjunction with these studies, our results further demonstrated that the hippocampal MRI data could provide informative measures for the prediction of MCI subjects‚Äô timing of progression to AD dementia.</p>
<p>In the present study, the training imaging data were collected using 1.5T scanners and the testing imaging data were collected using 3T scanners. The deep learning features of 1.5 and 3T scans of the same ADNI 1 subjects highly correlated with each other and showed high comparability in their predicted risk scores, demonstrating that the deep learning features were robust to magnetic field strength differences. Therefore, the differences between the training data and testing data in the scanners‚Äô magnetic field strength minimally affected the prediction performance. We postulate that the image intensity normalization used in our study might minimize the difference caused by the scanner‚Äôs magnetic field strength.</p>
<p>Our deep learning models could be used to predict AD progression risks for individuals with MRI scans collected following the ADNI imaging protocol. The whole pipeline of the proposed prognostic model is automatic. It is not sensitive to hippocampus segmentation, as only a bounding box containing hippocampus is required. The deep learning feature extraction and prognosis is efficient on both modern GPU and CPU (within 1 second) once the trained model is obtained. Particularly, for each subject, it takes about 0.011 second on a GPU or about 0.463 second on a CPU to compute deep learning features, and it takes 0.1 millisecond to obtain a prognosis result on a CPU. This deep learning tool can be used across platforms, including cloud computing, once they are containerized using docker.</p>
<p>The approach here offers a straightforward and computationally rapid means for a clinician to stratify MCI patients about the likelihood of progression within a particular timeframe. This could have significant impact on family and patient planning. In light of the fact that prediction accuracy is similar to prediction from AŒ≤ measures, this approach may obviate the need for some measures in the clinical setting with the advantage of being non-invasive, as opposed to lumbar puncture, and less expensive, as compared to amyloid PET.</p>
<p>Although the proposed prognostic model has achieved better performance than state-of-the-art alternative imaging feature extraction methods for AD prognosis, further efforts are needed in following aspects. First, the current study focused on the hippocampus, it is expected to obtain improved prognostic performance when the deep learning method is applied to the whole brain MRI data. Second, the current study focused on predicting MCI subjects‚Äô progression to AD dementia, but the proposed framework could be applied to other clinical endpoints, such as predicting NC subject‚Äôs progression to MCI [56] or cognitive decline, which could be useful in preclinical AD studies and facilitate subject screening in clinical trial. Third, only data at baseline were used in the current study, and we expect that the prognostic performance could be boosted if longitudinal data are incorporated into the model. Fourth, the current study focused on the prediction of boundaries between MCI and AD, which may not be well equipped to characterize the AD continuum [57].</p>
<p>The cognitive measures demonstrated better performance than the imaging measures for predicting the AD dementia progression as cognition is core component of the diagnosis of dementia, which results in circularity of using these measures in this type of prediction. Future work could focus more on predicting cognitive change which may be less susceptible to these circularity arguments. Additionally, the present study focused on the imaging features and did not fully explored other cognitive measures that might be even more informative for the prediction of MCI progression, such as RAVLT delayed recall, or impairment in other cognitive domains, such as executive function. Finally, changes in activities of daily living are also reflective progression from MCI to dementia and therefore could further add prediction.</p>
<p>Although our method could build time-to-event prediction models with continuous timing information, our prediction model largely captured the AD progression on intervals of 6 months because the training subjects were followed every 6 months. Since most of the ADNI MCI subjects progressed to AD dementia within 36 months, our prediction model might be driven to focus more on the advanced MCI subjects and to identify information relevant to late MCI. Moreover, although quantitative results have demonstrated that the prognostic model was robust to imaging data collected by scanners with different magnetic field strength, other potential confounders regarding subject heterogeneity such as atypical forms of AD require further investigation using datasets in clinical settings. One source of comfort related to heterogeneity of imaging acquisition for the viability of this approach is that quantitative results have demonstrated that the deep learning imaging features were robust to imaging data collected using scanners with different magnetic field strengths. It should be noted also that ADNI was designed to mimic a clinical trial and that is an additional context, outside of clinical practice, in which the findings here are relevant for potentially determining inclusion in an intervention study. Finally, although our study showed that the deep hippocampal features have considerable advantages compared to conventional methods such as hippocampal volume, the hippocampus as a structure might be limited in sensitivity and specificity for AD prediction and future research should consider further relevant regions.</p>
<p>In conclusion, the deep learning method for early prognosis of AD dementia could achieve promising performance, help distinguish MCI subjects with different progression patterns, and identify MCI subjects with higher risk to develop AD dementia, thus providing a cost effective and accurate means for prognosis and potentially to facilitate enrollment in clinical trials with individuals likely to progress within a specific temporal period.</p>
</blockquote>
<h2 id="references">References<a class="headerlink" href="#references" title="Permanent link">¬∂</a></h2>
<p>[1] Langa K, Levine D. The diagnosis and management of mild cognitive impairment: a clinical review. JAMA. 2014;312.
[2] Desikan RS, Cabral HJ, Settecase F, Hess CP, Dillon WP, Glastonbury CM, et al. Automated MRI measures predict progression to Alzheimer's disease. Neurobiology of aging. 2010;31:1364-74.
[3] Filipovych R, Davatzikos C, Alzheimer's Disease Neuroimaging I. Semi-supervised pattern classification of medical images: application to mild cognitive impairment (MCI). NeuroImage. 2011;55:1109-19.
[4] Moradi E, Pepe A, Gaser C, Huttunen H, Tohka J, Alzheimer's Disease Neuroimaging I. Machine learning framework for early MRI-based Alzheimer's conversion prediction in MCI subjects. NeuroImage. 2015;104:398-412.
[5] de Vos F, Schouten TM, Hafkemeijer A, Dopper EG, van Swieten JC, de Rooij M, et al. Combining multiple anatomical MRI measures improves Alzheimer's disease classification. Human brain mapping. 2016;37:1920-9.
[6] Hu K, Wang Y, Chen K, Hou L, Zhang X. Multi-scale features extraction from baseline structure MRI for MCI patient classification and AD early diagnosis. Neurocomputing. 2016;175, Part A:132-45.
<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5511557/pdf/nihms874419.pdf" title="Rathore, S., Habes, M., Iftikhar, M.A., Shacklett, A. and Davatzikos, C., 2017. A review on neuroimaging-based classification studies and associated feature extraction methods for Alzheimer's disease and its prodromal stages. NeuroImage, 155, pp.530-548.">7</a> Rathore S, Habes M, Iftikhar MA, Shacklett A, Davatzikos C. A review on neuroimaging-based classification studies and associated feature extraction methods for Alzheimer's disease and its prodromal stages. NeuroImage. 2017;155:530-48.
[8] Fan Y, Resnick SM, Wu XY, Davatzikos C. Structural and functional biomarkers of prodromal Alzheimer's disease: A high-dimensional pattern classification study. NeuroImage. 2008;41:277-85. [9] Davatzikos C, Fan Y, Wu X, Shen D, Resnick SM. Detection of prodromal Alzheimer's disease via
pattern classification of magnetic resonance imaging. Neurobiology of aging. 2008;29:514-23.
[10] Fan Y, Batmanghelich N, Clark CM, Davatzikos C, Initia ADN. Spatial patterns of brain atrophy in MCI patients, identified via high-dimensional pattern classification, predict subsequent cognitive decline. NeuroImage. 2008;39:1731-43.
[11] Misra C, Fan Y, Davatzikos C. Baseline and longitudinal patterns of brain atrophy in MCI patients, and their use in prediction of short-term conversion to AD: Results from ADNI. NeuroImage. 2009;44:1415-22.
[12] Barnes DE, Cenzer IS, Yaffe K, Ritchie CS, Lee SJ, Alzheimer's Disease Neuroimaging I. A point- based tool to predict conversion from mild cognitive impairment to probable Alzheimer's disease. Alzheimer's &amp; dementia : the journal of the Alzheimer's Association. 2014;10:646-55.
[13] Kong D, Giovanello KS, Wang Y, Lin W, Lee E, Fan Y, et al. Predicting Alzheimer‚Äôs disease using combined imaging-whole genome SNP data. Journal of Alzheimer's Disease. 2015;46:695-702.
[14] Li K, O'Brien R, Lutz M, Luo S, Alzheimer's Disease Neuroimaging I. A prognostic model of Alzheimer's disease relying on multiple longitudinal measures and time-to-event data. Alzheimer's &amp; dementia : the journal of the Alzheimer's Association. 2018;14:644-51.
[15] Li S, Okonkwo O, Albert M, Wang M-C. Variation in variables that predict progression from MCI to AD dementia over duration of follow-up. American journal of Alzheimer's disease (Columbia, Mo). 2013;2:12-28.
[16] Khachaturian AS, Corcoran CD, Mayer LS, Zandi PP, Breitner JS, Cache County Study I. Apolipoprotein e Œµ4 count affects age at onset of alzheimer disease,but not lifetime susceptibility: The cache county study. Archives of General Psychiatry. 2004;61:518-24.
[17] Weiner MW, Veitch DP, Aisen PS, Beckett LA, Cairns NJ, Green RC, et al. Recent publications from the Alzheimer's Disease Neuroimaging Initiative: Reviewing progress toward improved AD clinical trials. Alzheimer's &amp; dementia : the journal of the Alzheimer's Association. 2017;13:e1-e85.
[18] Weiner MW, Veitch DP, Aisen PS, Beckett LA, Cairns NJ, Green RC, et al. The Alzheimer's Disease Neuroimaging Initiative 3: Continued innovation for clinical trial improvement. Alzheimer's &amp; dementia : the journal of the Alzheimer's Association. 2017;13:561-71.
[19] Weiner MW, Veitch DP, Aisen PS, Beckett LA, Cairns NJ, Cedarbaum J, et al. 2014 Update of the Alzheimer's Disease Neuroimaging Initiative: A review of papers published since its inception. Alzheimer's &amp; dementia : the journal of the Alzheimer's Association. 2015;11:e1-120.
[20] Ellis KA, Bush AI, Darby D, De Fazio D, Foster J, Hudson P, et al. The Australian Imaging, Biomarkers and Lifestyle (AIBL) study of aging: methodology and baseline characteristics of 1112 individuals recruited for a longitudinal study of Alzheimer's disease. International psychogeriatrics. 2009;21:672- 87.
[21] Hao Y, Wang T, Zhang X, Duan Y, Yu C, Jiang T, et al. Local label learning (LLL) for subcortical structure segmentation: Application to hippocampus segmentation. Human brain mapping. 2014;35:2674-97.
[22] Boccardi M, Bocchetta M, Morency FC, Collins DL, Nishikawa M, Ganzola R, et al. Training labels for hippocampal segmentation based on the EADC-ADNI harmonized hippocampal protocol. Alzheimers &amp; Dementia. 2015;11:175-83.
[23] He K, Zhang X, Ren S, Sun J. Deep Residual Learning for Image Recognition. 2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)2016. p. 770-8.
[24] Zhou B, Khosla A, Lapedriza A, Oliva A, Torralba A. Learning deep features for discriminative localization. Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition2016. p. 2921-9.
[25] Ioffe S, Szegedy C. Batch Normalization: Accelerating Deep Network Training by Reducing Internal Covariate Shift. In: Bach FR, Blei DM, editors. ICML: JMLR.org; 2015. p. 448-56.
[26] Tibshirani R. The lasso method for variable selection in the Cox model. Statistics in medicine. 1997;16:385-95.
[27] Royston P. Estimating a smooth baseline hazard function for the Cox model. London: Department of Statistical Science, University College London. 2011.
[28] Cox DR. Regression models and life-tables. Breakthroughs in statistics: Springer; 1992. p. 527-41.
[29] van Griethuysen JJM, Fedorov A, Parmar C, Hosny A, Aucoin N, Narayan V, et al. Computational Radiomics System to Decode the Radiographic Phenotype. Cancer research. 2017;77:e104-e7.
[30] Barandiaran I. The random subspace method for constructing decision forests. IEEE transactions on pattern analysis and machine intelligence. 1998;20.
[31] Harrell FE, Jr., Lee KL, Mark DB. Multivariable prognostic models: issues in developing models, evaluating assumptions and adequacy, and measuring and reducing errors. Statistics in medicine. 1996;15:361-87.
[32] Blanche P, Dartigues JF, Jacqmin-Gadda H. Estimating and comparing time-dependent areas under receiver operating characteristic curves for censored event times with competing risks. Statistics in medicine. 2013;32:5381-97.
[33] Heagerty PJ, Lumley T, Pepe MS. Time-dependent ROC curves for censored survival data and a diagnostic marker. Biometrics. 2000;56:337-44.
[34] Kang L, Chen W, Petrick NA, Gallas BD. Comparing two correlated C indices with right-censored survival outcome: a one-shot nonparametric approach. Statistics in medicine. 2015;34:685-703.
[35] Li F, Tran L, Thung KH, Ji S, Shen D, Li J. A Robust Deep Model for Improved Classification of AD/MCI Patients. IEEE journal of biomedical and health informatics. 2015;19:1610-6.
[36] Ithapu VK, Singh V, Okonkwo OC, Chappell RJ, Dowling NM, Johnson SC, et al. Imaging-based enrichment criteria using deep learning algorithms for efficient clinical trials in mild cognitive impairment. Alzheimer's &amp; Dementia. 2015;11:1489-99.
[37] Amoroso N, Diacono D, Fanizzi A, La Rocca M, Monaco A, Lombardi A, et al. Deep learning reveals Alzheimer's disease onset in MCI subjects: Results from an international challenge. Journal of neuroscience methods. 2018;302:3-9.
[38] Suk HI, Lee SW, Shen D, Alzheimer's Disease Neuroimaging I. Hierarchical feature representation and multimodal fusion with deep learning for AD/MCI diagnosis. NeuroImage. 2014;101:569-82.
[39] Wolk DA, Sadowsky C, Safirstein B, et al. Use of flutemetamol f 18‚Äìlabeled positron emission tomography and other biomarkers to assess risk of clinical progression in patients with amnestic mild cognitive impairment. JAMA Neurology. 2018.
[40] Chupin M, Gerardin E, Cuingnet R, Boutet C, Lemieux L, Lehericy S, et al. Fully automatic hippocampus segmentation and classification in Alzheimer's disease and mild cognitive impairment applied on data from ADNI. Hippocampus. 2009;19:579-87.
[41] Devanand DP, Bansal R, Liu J, Hao X, Pradhaban G, Peterson BS. MRI hippocampal and entorhinal cortex mapping in predicting conversion to Alzheimer's disease. NeuroImage. 2012;60:1622-9.
[42] Ben Ahmed O, Benois-Pineau J, Allard M, Ben Amar C, Catheline G. Classification of Alzheimer‚Äôs
disease subjects from MRI using hippocampal visual features. Multimedia Tools and Applications.
2015;74:1249-66.
[43] Aderghal K, Boissenin M, Benois-Pineau J, Catheline G, Afdel K. Classification of sMRI for AD
Diagnosis with Convolutional Neuronal Networks: A Pilot 2-D+e Study on ADNI. In: Amsaleg L, Gu√∞mundsson G√û, Gurrin C, JoÃÅnsson B√û, Satoh Si, editors. MultiMedia Modeling: 23rd International Conference, MMM 2017, Reykjavik, Iceland, January 4-6, 2017, Proceedings, Part I. Cham: Springer International Publishing; 2017. p. 690-701.
[44] Tsao S, Gajawelli N, Zhou J, Shi J, Ye J, Wang Y, et al. Feature selective temporal prediction of Alzheimer's disease progression using hippocampus surface morphometry. Brain and behavior. 2017;7:e00733.
[45] Li S, Shi F, Pu F, Li X, Jiang T, Xie S, et al. Hippocampal shape analysis of Alzheimer disease based on machine learning methods. AJNR Am J Neuroradiol. 2007;28:1339-45.
[46] Costafreda SG, Dinov ID, Tu Z, Shi Y, Liu C-Y, Kloszewska I, et al. Automated hippocampal shape analysis predicts the onset of dementia in mild cognitive impairment. NeuroImage. 2011;56:212-9.
[47] Gerardin E, Chetelat G, Chupin M, Cuingnet R, Desgranges B, Kim H-S, et al. Multidimensional classification of hippocampal shape features discriminates Alzheimer's disease and mild cognitive impairment from normal aging. NeuroImage. 2009;47:1476-86.
[48] Sorensen L, Igel C, Liv Hansen N, Osler M, Lauritzen M, Rostrup E, et al. Early detection of Alzheimer's disease using MRI hippocampal texture. Human brain mapping. 2016;37:1148-61.
[49] Li H, Habes M, Fan Y. Deep Ordinal Ranking for Multi-Category Diagnosis of Alzheimer's Disease
using Hippocampal MRI data. arXiv: 170901599. 2017.
[50] Adler DH, Wisse LE, Ittyerah R, Pluta JB, Ding S-L, Xie L, et al. Characterizing the human
hippocampus in aging and Alzheimer‚Äôs disease using a computational atlas derived from ex vivo
MRI and histology. Proceedings of the National Academy of Sciences. 2018;115:4252-7.
[51] Martin SB, Smith CD, Collins HR, Schmitt FA, Gold BT. Evidence that volume of anterior medial temporal lobe is reduced in seniors destined for mild cognitive impairment. Neurobiology of aging.
2010;31:1099-106.
[52] Harrison TM, Burggren AC, Small GW, Bookheimer SY. Altered memory-related functional
connectivity of the anterior and posterior hippocampus in older adults at increased genetic risk for
Alzheimer's disease. Human brain mapping. 2016;37:366-80.
[53] Das SR, Pluta J, Mancuso L, Kliot D, Yushkevich PA, Wolk DA. Anterior and posterior MTL networks
in aging and MCI. Neurobiology of aging. 2015;36 Suppl 1:S141-50, S50 e1.
[54] West MJ, Coleman PD, Flood DG, Troncoso JC. Differences in the pattern of hippocampal neuronal
loss in normal ageing and Alzheimer's disease. Lancet. 1994;344:769-72.
[55] Jack CR, Jr., Bennett DA, Blennow K, Carrillo MC, Dunn B, Haeberlein SB, et al. NIA-AA Research Framework: Toward a biological definition of Alzheimer's disease. Alzheimer's &amp; dementia : the
journal of the Alzheimer's Association. 2018;14:535-62.
[56] Albert M, Zhu Y, Moghekar A, Mori S, Miller MI, Soldan A, et al. Predicting progression from normal
cognition to mild cognitive impairment for individuals at 5 years. Brain : a journal of neurology. 2018. [57] Aisen PS, Cummings J, Jack CR, Morris JC, Sperling R, Frolich L, et al. On the path to 2025:
understanding the Alzheimer's disease continuum. Alzheimers Res Ther. 2017;9.</p>
<h2 id="_5"><a class="headerlink" href="#_5" title="Permanent link">¬∂</a></h2>
<!-- -------------------------------------------- -->

<!-- toc -->

<!-- ref -->

<!-- fig -->

<!-- term -->

<style type="text/css">
    img{width: 50%; float: right;}
</style>
              
            </div>
          </div>
          <footer>
  
    <div class="rst-footer-buttons" role="navigation" aria-label="footer navigation">
      
        <a href="../190604_PapeKatrin_2019/" class="btn btn-neutral float-right" title="190604 Pape, Katrin, 2019">Next <span class="icon icon-circle-arrow-right"></span></a>
      
      
        <a href="../190630_MasseNicolasY_2019/" class="btn btn-neutral" title="190630 Masse, Nicolas Y., 2019"><span class="icon icon-circle-arrow-left"></span> Previous</a>
      
    </div>
  

  <hr/>

  <div role="contentinfo">
    <!-- Copyright etc -->
    
      <p>Copyright &copy; 2018 - 2019 <a href="https://github.com/shumez">shumez</a>
</p>
    
  </div>

  Built with <a href="http://www.mkdocs.org">MkDocs</a> using a <a href="https://github.com/snide/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>.
</footer>
      
        </div>
      </div>

    </section>

  </div>

  <div class="rst-versions" role="note" style="cursor: pointer">
    <span class="rst-current-version" data-toggle="rst-current-version">
      
      
        <span><a href="../190630_MasseNicolasY_2019/" style="color: #fcfcfc;">&laquo; Previous</a></span>
      
      
        <span style="margin-left: 15px"><a href="../190604_PapeKatrin_2019/" style="color: #fcfcfc">Next &raquo;</a></span>
      
    </span>
</div>
    <script>var base_url = '..';</script>
    <script src="../js/theme.js" defer></script>
      <script src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML" defer></script>
      <script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-MML-AM_CHTML" defer></script>
      <script src="../search/main.js" defer></script>

</body>
</html>
